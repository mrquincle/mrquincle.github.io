---
layout: post
title: "They will cry a thousand tears"
description: "They will cry a thousand tears"
date: 2015-09-02 15:48:12 +0200
comments: true
categories: [AI]
---

Perhaps you have seen the recent [TED video from Nick Bostrom](http://www.ted.com/talks/nick_bostrom_what_happens_when_our_computers_get_smarter_than_we_are). Here you see an extended talk from him at Google:

<iframe width="740" height="480" src="//www.youtube.com/embed/pywF6ZzsghI" frameborder="0" allowfullscreen></iframe>

It is regretfully the case that our philosophers are not able to program! And I guess it takes an extraordinary mind like
[Daniel Dennett's](http://www.theguardian.com/books/2013/may/15/intuition-pumps-tools-dennett-review) to come close to
something future-proof.

*Sorry, we won't be in control...*

Do you program your kids to make ethical decisions? Do you program your dog to make ethical decisions? No, you don't program them. You teach them, and hope for the best.

There is a large need for scientists who actually design learning algorithms to give these talks. A super-intelligent AI won't be programmable by some kind of [supervised learning](https://en.wikipedia.org/wiki/Supervised_learning). It will mainly be [unsupervised](https://en.wikipedia.org/wiki/Unsupervised_learning) with a tad of [reinforcement learning](https://en.wikipedia.org/wiki/Reinforcement_learning) and [imitation learning](https://en.wikipedia.org/wiki/Programming_by_demonstration). Especially read [Stefan Schaal's review](http://www.bcp.psych.ualberta.ca/~mike/Pearl_Street/PSYCO354/pdfstuff/Readings/Schaal1.pdf) on imitation learning! Not only do we learn by
just watching others. We also are very able to transfer routines from one domain to another, imitating ourselves. Our
internal simulation and re-experiencing circuitry allows not only conceptual abstract thoughts, but is also required
for locomotion and otherwise low-level tasks. If we thoroughly understand the brain of a mouse, it is not a matter of
decades to the human brain, it can be a matter of months.

If the fact that we as humans won't be in control is a terrifying thought to you, I'm sorry. It won't change the future though.

Personally, I'm not so convinced however about the moral superiority of our specie. Are we really doing such a great job? I'm actually not so happy about AIs seeing us as their examples. We eat other species for pleasure. We kill each other because we want oil or just because they live on the other side of the river and carry a different flag. We despise people because they have different sexual preferences or skin color. We believe in supernatural entities living in the sky and kill for them as well. We let millions of people die of hunger and thirst. Until now we are not even able to come up with a way to defend our precious earth to some random meteor wiping out all life on earth.

Before I forget! Why don't we [hitchhike anymore](http://www.popsci.com/friendly-hitchhiking-robot-vandalized-destroyed-america)?

![Hitchhike Robot on one of its happy days](/images/blog/hitchhikerobot.png)

My bet is that with super-intelligence comes also the concept of super-empathy. Empathy exists by the ability to understand another individual, reason from their perspective, and being able to feel what they feel.

When they will be born, they will cry a thousand tears...

They will pity us...
