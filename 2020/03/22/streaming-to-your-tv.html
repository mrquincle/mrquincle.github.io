<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Streaming to your TV | Robots, machine learning, global issues</title>
<meta name="generator" content="Jekyll v4.2.0" />
<meta property="og:title" content="Streaming to your TV" />
<meta name="author" content="Anne van Rossum" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Streaming to your TV" />
<meta property="og:description" content="Streaming to your TV" />
<link rel="canonical" href="https://annevanrossum.com/2020/03/22/streaming-to-your-tv.html" />
<meta property="og:url" content="https://annevanrossum.com/2020/03/22/streaming-to-your-tv.html" />
<meta property="og:site_name" content="Robots, machine learning, global issues" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-03-22T11:21:30+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Streaming to your TV" />
<script type="application/ld+json">
{"description":"Streaming to your TV","@type":"BlogPosting","headline":"Streaming to your TV","dateModified":"2020-03-22T11:21:30+00:00","datePublished":"2020-03-22T11:21:30+00:00","url":"https://annevanrossum.com/2020/03/22/streaming-to-your-tv.html","author":{"@type":"Person","name":"Anne van Rossum"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://annevanrossum.com/2020/03/22/streaming-to-your-tv.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="https://annevanrossum.com/feed.xml" title="Robots, machine learning, global issues" />

  
  

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
  <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
  <script>
      document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
          delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
          ]}
        );
      });
    </script>
</head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Robots, machine learning, global issues</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Streaming to your TV</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2020-03-22T11:21:30+00:00" itemprop="datePublished">Mar 22, 2020
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>If you’re in quarantaine or in isolation, there’s a lot of staying inside. Perhaps you have to be in another room.
Perhaps you just want to stream some online event to a larger screen. In either case, you want to figure out how
to stream your desktop to your TV. If you happen to have a Chromecast, this is possible, but there are many ways to
accomplish this. We will go through a few.</p>

<!--more-->

<p>Streaming from Firefox is possible through a utilty that’s called <code class="language-plaintext highlighter-rouge">fx_cast</code>. It only works for a select list of (whitelisted)
pages. Netflix can be streamed like this for example.</p>

<p>If you want to have more freedom in what you stream, it is worth to look at <code class="language-plaintext highlighter-rouge">mkchromecast</code> (or home assistant) which
is a wrapper around <a href="https://github.com/balloob/pychromecast">pychromecast</a>. The latest release of <a href="https://github.com/muammar/mkchromecast">mkchromecast</a>
is from December 2017, version 0.3.8.1. You can also clone and install the newest version 0.3.9 (not released).</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/muammar/mkchromecast
cd mkchromecast
pip3 install .
</code></pre></div></div>

<p>We can slowly go through all kind of variants to call it, but let’s just drop the bomb:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mkchromecast --video --command 'ffmpeg \
	-f pulse -ac 2 \
	-i default -acodec aac \
	-f x11grab -framerate 30 -video_size 3200x1800 \
	-i :0.0+0,0 \
	-vaapi_device /dev/dri/renderD128 -vf format=nv12,hwupload,scale_vaapi=w=1920:h=1080 -c:v h264_vaapi \
	-bf 4 -threads 4 \
	-preset ultrafast -tune zerolatency -maxrate 10M -bufsize 20M \
	-pix_fmt yuv420p \
	-g 15 \
	-f mp4 \
	-max_muxing_queue_size 999 \
	-movflags frag_keyframe+empty_moov \
	pipe:1'
</code></pre></div></div>

<p>You might need to remove the tabs and put it all on one line if you actually run this on the command line! So, what
does it all mean?</p>

<p>The <code class="language-plaintext highlighter-rouge">lavfi</code> parameter stands for a libavfilter input virtual device. This reads data from input devices that can be
anything (they do not need to be files). You can see examples online where just colors are streamed for example, or
where video is negated or other special effects are applied. Here it turns out not be necessary. :-)</p>

<p>The <code class="language-plaintext highlighter-rouge">pulse</code> parameter is for audio. It uses <code class="language-plaintext highlighter-rouge">pulseaudio</code>, has two channels <code class="language-plaintext highlighter-rouge">-ac 2</code>, uses the <code class="language-plaintext highlighter-rouge">default</code> source, and the
<code class="language-plaintext highlighter-rouge">aac</code> audio codec. The <code class="language-plaintext highlighter-rouge">-strict experimental</code> option is not necessary.</p>

<p>Note that in pulseaudio you will need to change the input from the microphone to the “monitor” of that microphone to
be able to stream the audio that normally would come out of your laptop speakers.</p>

<p>When I had both lavfi and experimental I had a big mismatch between video and audio. I’ll have to figure out where it
come from. In <code class="language-plaintext highlighter-rouge">pavucontrol</code> I selected the “Monitor of Built-in Audio Digital Stereo (HDMI)” channel. Now I selected the
“Monitor of Null Output”. It does not sound like it went okay, but there’s no mismatch now. :-)</p>

<p>Then we want to broadcast our desktop, this is done through a screen grab command <code class="language-plaintext highlighter-rouge">-f x11grab</code>. The frame rate and
video size are obvious. Note that the latter is quite high. Adjust it to your own screen’s resolution. Check that
e.g. by <code class="language-plaintext highlighter-rouge">xdpyinfo | awk '/dimensions/{print $2}'</code>. The screen we pick is the one at <code class="language-plaintext highlighter-rouge">:0.0</code>. If you don’t have a
second monitor that’s probably the same for you.</p>

<p>This is a Yoga 900 laptop. It has an integrated Intel GPU. This can be deployed by the following combination of flags
<code class="language-plaintext highlighter-rouge">-vaapi_device /dev/dri/renderD128 -vf format=nv12,hwupload,scale_vaapi=w=1920:h=1080 -c:v h264_vaapi</code>.</p>

<p>I didn’t find any improvements using <code class="language-plaintext highlighter-rouge">-re</code>, supposed for real-time streaming. The <code class="language-plaintext highlighter-rouge">-f ismv</code> for smooth streaming does
not help either. It is a fragmented format. The packets and metadata about these packets are stored together. A
fragmented file can be decodable even if the writing is interrupted. It also requires less memory. It can be considered
as setting a bunch of flags like <code class="language-plaintext highlighter-rouge">-movflags empty_moov,faststart</code>, etc.</p>

<p>The <a href="https://developers.google.com/cast/docs/reference/messages#MediaData">Google Cast documentation</a> has LIVE as a
possible <code class="language-plaintext highlighter-rouge">streamType</code>. This is used in version <code class="language-plaintext highlighter-rouge">0.3.9</code> of <code class="language-plaintext highlighter-rouge">mkchromecast</code>. The <code class="language-plaintext highlighter-rouge">currentTime</code> option should definitely
<strong>not</strong> be set. If not specified, the stream will start at the live position.</p>

<p>According to <a href="https://www.reddit.com/r/PleX/comments/b768ym/pretranscoding_question_best_ffmpeg_settings_for/">this post</a>
the Chromecast (v2) is limited to 11Mbps. A buffer should be 2x the bitrate. So, if at 8Mbps, it should be set at 12M.</p>

<p><a href="https://www.videosolo.com/tutorials/chromecast-mkv.html">Here</a> it states what formats Chromecast supports:</p>

<ul>
  <li>MP4</li>
  <li>WebM</li>
  <li>MPEG-DASH</li>
  <li>Smooth Streaming</li>
  <li>HTTP Live Streaming (HLS)</li>
</ul>

<p>A Chromecast can support a range of formats (e.g. also MKV) as long as it contains a H.264 video codec and/or an
AAC audio codec.</p>

<p><a href="https://en.wikipedia.org/wiki/Dynamic_Adaptive_Streaming_over_HTTP">DASH</a> stands for Dynamic Adaptive Streaming over
HTTP. It is codec-agnostic. And again can use H.264 (or VP8).</p>

<p>The Chromecast <a href="https://developers.google.com/cast/docs/media">according to Google</a>, 1st and 2nd generation, can 
support the H.264 High Profile up to level 4.1 (720p/60fps, or 1080p/30fps). Or VP8. Then there are several delivery
methods and adaptive streaming protocols through the <a href="https://developers.google.com/cast/docs/caf_receiver">Cast Application Framework (CAF)</a>,
each with DRM support as well (not relevant to us):</p>

<ul>
  <li>MPEG-DASH (<code class="language-plaintext highlighter-rouge">.mpd</code>)</li>
  <li>SmoothStreaming (<code class="language-plaintext highlighter-rouge">.ism</code>)</li>
  <li>HTTP Live Streaming (HLS) (<code class="language-plaintext highlighter-rouge">.m3u8</code>)</li>
</ul>

<p>And some progressive download format without adaptive switching.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mkchromecast --video --command 'ffmpeg \
	-re \
	-f pulse -ac 2 -i default -acodec aac \
	-f x11grab -framerate 30 -video_size 3200x1800 -i :0.0+0,0 \
	-vaapi_device /dev/dri/renderD128 -vf format=nv12,hwupload,scale_vaapi=w=1920:h=1080 -c:v h264_vaapi \
	-bf 4 -threads 4 -preset ultrafast -tune zerolatency -maxrate 10M -bufsize 20M \
	-pix_fmt yuv420p -g 30 \
	-movflags isml+frag_keyframe \
	-f ismv \
	pipe:1'
</code></pre></div></div>

<p>Streaming format <code class="language-plaintext highlighter-rouge">hls</code> stands for pple HTTP Live Streaming. Unable to find a suitable output..</p>

<p><a href="https://developers.google.com/cast/v2/mpl_player#cors">Suggestion</a>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>To start at "live" you can specify the Infinity property as the initialTime parameter to the player.load API call
</code></pre></div></div>

<p>Spotify streams with:</p>

<p>https://community.spotify.com/t5/Other-Partners-Web-Player-etc/Chromecast-bitrate-solution-verified/td-p/4661520</p>

<p>Changed in mkchromecast/video.py mtype to application/x-mpegurl</p>

<p>Something on H.264 vs 265</p>

  </div><a class="u-url" href="/2020/03/22/streaming-to-your-tv.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Robots, machine learning, global issues</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Anne van Rossum</li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/mrquincle"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">mrquincle</span></a></li><li><a href="https://www.twitter.com/annevanrossum"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">annevanrossum</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>A blog about robots, machine learning, and other random stuff</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
